---
title: "TA"
output: html_notebook
---



```{r}
# Library Load
library(tidyverse)
library(dynlm)
library(forecast)
library(vtable)
library (lubridate)
library(scales)
library(patchwork)
library(stats)
library(tseries)
library(jtools)
```

```{r}

# loads csv into a base data frame
base_housing_data <- read_csv("fmhpi_master_file.csv")

# the following code will filter the base data_housing_data building a data frame for only the Seattle-Tacoma-Bellevue WA area from 1975 to 2019. This "pre-covid" time frame ends in Dec 2019. While the WHO did not declare COVID-19 a pandemic until March 2020, the effect of the disease on work, employment, etc. was already manifesting in February (Changes to the following code per the Professor's guidance 11/18/21). 

base_puget_precovid_data <- filter(base_housing_data, GEO_Name == 
                            'Seattle-Tacoma-Bellevue WA') %>% 
                            filter(Year <= 2019)

# Creates a new YearMonth date variable as a date class (day is set to 01)

base_puget_precovid_data$YearMonth <- as.Date(with(base_puget_precovid_data,paste(Year, Month, 1, sep="-")),"%Y-%m-%d") 
  
# Narrows the number of variables by removing the Code variables and then reorders the variables. The not seasonally adjust variable was removed per the Professor's guidance 11/18/21)
wip_puget_precovid_data <- base_puget_precovid_data %>% 
  select(YearMonth, Index_SA)
```

```{r}
# The following code will determine if the data is stationary 

#  The following converts the data to a time series using seasonally adjusted data 
index_sa_ts <- ts(wip_puget_precovid_data$Index_SA, frequency = 12, start = c(1975))

# The following plots the seasonally adjusted index (sa) then builds plots for  ACF.

plot(index_sa_ts, main = 'Pre-Covid Freddie Mac Seasonally 
     Adjusted Housing Price Index from 2011 - 2019 ', ylab = 'Housing Index', xlab = 'Year')

ggAcf(index_sa_ts)
ggPacf(index_sa_ts)

```
## Observation(s):
1. The plot does not display a tradition stationary process profile.   
2. The ACF indications that the process is not stationary.

```{r}
# The following code log diff's the sa index to make it stationary.
log_diff_sa_ts <- diff(log(index_sa_ts))

plot(log_diff_sa_ts, xlab = 'Years', ylab = 'Change in Precetage')
abline(h = '.0053')

```
## Observation(s):
1. The plot appears to show a stationary profile.
2. The log diff time series values are normally distributed with a mean of .0053 and a standard deviation of .0077. 

```{r}
# The following code will conduct an Augmented Dickey-Fuller test to determine is the series is indeed stationary.

adf.test(log_diff_sa_ts)

```
## Observation(s): 
 1.  The series is stationary.  The Dickey-Fuller critical value is -2.87 (~500 observations, 5% without trend, with trend is -2.41). The order 1 diff time series' stat was -3.2757, well below the critical value and in the H~0~ rejection area. 

```{r}
# The following builds the ACF and PACF plots for the stationary time series plots to determine the type of model to use.

ggAcf(log_diff_sa_ts) +
  ylim(c(-.5, 1)) +
  theme_classic() + 
  ggtitle('ACF') +
  labs(y = ' ')


ggPacf(log_diff_sa_ts) +
  ylim(c(-.5, 1)) +
  theme_classic() + 
  ggtitle('PACF') +
  labs(y = ' ')

```
## Observation(s):
1. The ACF has a geometrically decaying correlation indicative of a AR model. 
2. The PACF has a significant drop off at lag 3, then another group of significant spikes between lags 12 and 17. 
3. The spike at 7 and 10 are not very significant and consider random variation.

## Conclusion(s): 
1. Might consider a AR(3) model or an extreme model of AR(16).  The AR(16) will most likely be a case of over fitting.  

```{r}

# The following creates the ts that will be used in the prediction sample. 
# Forecast horizon will be 21 (01/2020 - 05/2021). 

wip_puget_housing_obs <- filter(base_housing_data, GEO_Name == 
                            'Seattle-Tacoma-Bellevue WA') %>%  
                            select(Year, Month, Index_SA)

prediction_sample_ts <- ts(wip_puget_housing_obs$Index_SA, frequency = 12, start = c(1975, 1))

log_diff_prediction_ts <- diff(log(prediction_sample_ts))

covid_pand_housing_prediction_sample <- window(log_diff_prediction_ts, start = c(2020, 1))

```

# Model Assessment
```{r}
ar_3_model <-  dynlm(log_diff_sa_ts ~ 
                    stats::lag(log_diff_sa_ts, -1) +
                    # Used stats::lag because dplyr has a lag function 
                    # index_sa_ts is the original ts and not the log diff
                    stats::lag(log_diff_sa_ts, -2) + 
                    stats::lag(log_diff_sa_ts, -3), 
                    start = c(1975, 1), end = c(2019, 12))

summary(ar_3_model)
```
```{r}
# The following code assesses the residual for the AR(3) model.
ar_3_model_resid <- resid(ar_3_model)

ggAcf(ar_3_model_resid) +
  ylim(c(-.5, 1)) +
  theme_classic() + 
  ggtitle('ACF') +
  labs(main = 'AR(3) Residual ACF',y = ' ') 


ggPacf(ar_3_model_resid) +
  ylim(c(-.5, 1)) +
  theme_classic() + 
  ggtitle('PACF') +
  labs(main = 'AR(3) Residuals PACF', y = ' ')

ar_3_hist <- hist(ar_3_model_resid)

```
## Observation(s)
1. Both the ACF and PACF have numerous spikes that are of significance especially lag 8 and on.   
## Conclusion(s)
1. This is not the best model and will look at AR(16).

```{r}
ar_16_model <- dynlm(log_diff_sa_ts ~
                            stats::lag(log_diff_sa_ts, -1) +
                        # Used stats::lag because dplyr has a lag function 
                        # index_sa_ts is the original ts and not the log diff
                            stats::lag(log_diff_sa_ts, -2) + 
                            stats::lag(log_diff_sa_ts, -3) +
                            stats::lag(log_diff_sa_ts, -11) +
                            stats::lag(log_diff_sa_ts, -12) + 
                            stats::lag(log_diff_sa_ts, -13) + 
                            stats::lag(log_diff_sa_ts, -14) + 
                            stats::lag(log_diff_sa_ts, -15) + 
                            stats::lag(log_diff_sa_ts, -16),
                            start = c(1975, 1), end = c(2019, 12))
summary(ar_16_model)
```
```{r}
# The following code assesses the residual for the AR(16) model.
ar_16_model_resid <- resid(ar_16_model)

ggAcf(ar_16_model_resid) +
  ylim(c(-.5, 1)) +
  theme_classic() + 
  ggtitle('ACF') +
  labs(main = 'AR(3) Residual ACF',y = ' ') 


ggPacf(ar_16_model_resid) +
  ylim(c(-.5, 1)) +
  theme_classic() + 
  ggtitle('PACF') +
  labs(main = 'AR(3) Residuals PACF', y = ' ')

plot(fitted(ar_16_model), ar_16_model_resid)


ar_16_hist <- hist(ar_16_model_resid)

qqnorm(ar_16_model_resid); qqline(ar_16_model_resid)
qqnorm(ar_3_model_resid); qqline(ar_3_model_resid)


```

```{r}
AIC(ar_3_model)
AIC(ar_16_model)

BIC(ar_3_model)
BIC(ar_16_model)
```

```{r}
#  This following 3 models will use the same 3 Forecast Modeling method but use a AR(16) to investigate over-fitting. 

fcast_pandemic_rolling <- numeric(21) 
# Produces a list of 21 zeros. That is the count of observations from 01/2020 - 05/2020

for (i in 1:21) {
  pand_model_rolling <- dynlm(log_diff_sa_ts ~
                            stats::lag(log_diff_sa_ts, -1) +
                        # Used stats::lag because dplyr has a lag function 
                        # index_sa_ts is the original ts and not the log diff
                            stats::lag(log_diff_sa_ts, -2) + 
                            stats::lag(log_diff_sa_ts, -3) +
                            stats::lag(log_diff_sa_ts, -11) +
                            stats::lag(log_diff_sa_ts, -12) + 
                            stats::lag(log_diff_sa_ts, -13) + 
                            stats::lag(log_diff_sa_ts, -14) + 
                            stats::lag(log_diff_sa_ts, -15) + 
                            stats::lag(log_diff_sa_ts, -16),
                            start = c(1975, 1 + i), end = c(2019, 11 + i))
                        # There are 539 log/diff observations from 01/1975 to 12/2019
  
  fcast_pandemic_rolling[i] <- coef(pand_model_rolling)[1] +
                            coef(pand_model_rolling)[2] *   
                            log_diff_prediction_ts[538 + i] +
                        # coef 1 & 2 = Intercept and B1 (lag 1)
                            coef(pand_model_rolling)[3] * log_diff_prediction_ts[537 + i] +
                        # coef 3 = B2 (lag 2)
                            coef(pand_model_rolling)[4] * log_diff_prediction_ts[536 + i] +
                        # coef 4 = B3 (lag 3)
                            coef(pand_model_rolling)[5] * log_diff_prediction_ts[528 + i] +
                        # coef 5 = B4 (lag 11)
                            coef(pand_model_rolling)[6] * log_diff_prediction_ts[527 + i] +
                        # coef 6 = B5 (lag 12)
                            coef(pand_model_rolling)[7] * log_diff_prediction_ts[526 + i] +
                        # coef 7 = B6 (lag 13)
                            coef(pand_model_rolling)[8] * log_diff_prediction_ts[525 + i] + 
                        # coef 8 = B7 (lag 14)
                            coef(pand_model_rolling)[9] * log_diff_prediction_ts[524 + i] +
                        # coef 9 = B8 (lag 15)
                            coef(pand_model_rolling)[10] * log_diff_prediction_ts[523 + i]
                        # coef 10 = B9 (lag 16)
}

fcast_pandemic_rolling_ts <- ts(fcast_pandemic_rolling, frequency = 12, start = c(2020, 1))

# The following plots the AR(3) and AR(16) rolling forecasts against the actual observations.
plot(covid_pand_housing_prediction_sample)
lines(fcast_pandemic_rolling_ts, col = 'purple', lwd = 2)

```

```{r}
# This second model will use a Recursive Forecast Modeling method.

fcast_pandemic_recursive <- numeric(21) 
# Produces a list of 21 zeros. That is the count of observations from 01/2020 - 05/2020

for (i in 1:21) {
  pand_model_recursive <- dynlm(log_diff_sa_ts ~
                            stats::lag(log_diff_sa_ts, -1) +
                        # Used stats::lag because dplyr has a lag function 
                        # index_sa_ts is the original ts and not the log diff
                            stats::lag(log_diff_sa_ts, -2) + 
                            stats::lag(log_diff_sa_ts, -3) +
                            stats::lag(log_diff_sa_ts, -11) +
                            stats::lag(log_diff_sa_ts, -12) + 
                            stats::lag(log_diff_sa_ts, -13) + 
                            stats::lag(log_diff_sa_ts, -14) + 
                            stats::lag(log_diff_sa_ts, -15) + 
                            stats::lag(log_diff_sa_ts, -16), 
                            start = c(1975, 1), end = c(2019, 11 + i))
                        # There are 540 observations from 01/1975 to 12/2019
  
  fcast_pandemic_recursive[i] <- coef(pand_model_recursive)[1] +
                            coef(pand_model_recursive)[2] *   
                            log_diff_prediction_ts[539 + i] +
                        # coef 1 & 2 = Intercept and B1 (lag 1)
                            coef(pand_model_recursive)[3] * log_diff_prediction_ts[538 + i] +
                        # coef 3 = B2 (lag 2)
                            coef(pand_model_recursive)[4] * log_diff_prediction_ts[537 + i] +
                        # coef 4 = B3 (lag 3)
                            coef(pand_model_recursive)[5] * log_diff_prediction_ts[529 + i] +
                        # coef 5 = B4 (lag 11)
                            coef(pand_model_recursive)[6] * log_diff_prediction_ts[528 + i] +
                        # coef 6 = B5 (lag 12)
                            coef(pand_model_recursive)[7] * log_diff_prediction_ts[527 + i] +
                        # coef 7 = B6 (lag 13)
                            coef(pand_model_recursive)[8] * log_diff_prediction_ts[526 + i] + 
                        # coef 8 = B7 (lag 14)
                            coef(pand_model_recursive)[9] * log_diff_prediction_ts[525 + i] +
                        # coef 9 = B8 (lag 15)
                            coef(pand_model_recursive)[10] * log_diff_prediction_ts[524 + i]
                        # coef 10 = B9 (lag 16)
}

fcast_pandemic_recursive_ts <- ts(fcast_pandemic_recursive, frequency = 12, start = c(2020, 1))

# The following plots the AR(3) and AR(16) recursive forecasts against the actual observations.
plot(covid_pand_housing_prediction_sample)
lines(fcast_pandemic_recursive_ts, col = 'purple', lwd = 2)

```

```{r}
#  This first model will use a Fixed Forecast Modeling method.

fcast_pandemic_fixed <- numeric(21) 
# Produces a list of 21 zeros. That is the count of observations from 01/2020 - 05/2020

pand_model_fixed <- dynlm(log_diff_sa_ts ~
                            stats::lag(log_diff_sa_ts, -1) +
                        # Used stats::lag because dplyr has a lag function 
                        # index_sa_ts is the original ts and not the log diff
                            stats::lag(log_diff_sa_ts, -2) + 
                            stats::lag(log_diff_sa_ts, -3) +
                            stats::lag(log_diff_sa_ts, -11) +
                            stats::lag(log_diff_sa_ts, -12) + 
                            stats::lag(log_diff_sa_ts, -13) + 
                            stats::lag(log_diff_sa_ts, -14) + 
                            stats::lag(log_diff_sa_ts, -15) + 
                            stats::lag(log_diff_sa_ts, -16), 
                            start = c(1975, 1), end = c(2019, 12))
                        # The model will use only the observations from 01/1975 to 12/2019 
  

for (i in 1:21) {
  fcast_pandemic_fixed[i] <- coef(pand_model_fixed)[1] +
                            coef(pand_model_fixed)[2] *   
                            log_diff_prediction_ts[539 + i] +
                        # coef 1 & 2 = Intercept and B1 (lag 1)
                            coef(pand_model_fixed)[3] * log_diff_prediction_ts[538 + i] +
                        # coef 3 = B2 (lag 2)
                            coef(pand_model_fixed)[4] * log_diff_prediction_ts[537 + i] +
                        # coef 4 = B3 (lag 3)
                            coef(pand_model_fixed)[5] * log_diff_prediction_ts[529 + i] +
                        # coef 5 = B4 (lag 11)
                            coef(pand_model_fixed)[6] * log_diff_prediction_ts[528 + i] +
                        # coef 6 = B5 (lag 12)
                            coef(pand_model_fixed)[7] * log_diff_prediction_ts[527 + i] +
                        # coef 7 = B6 (lag 13)
                            coef(pand_model_fixed)[8] * log_diff_prediction_ts[526 + i] + 
                        # coef 8 = B7 (lag 14)
                            coef(pand_model_fixed)[9] * log_diff_prediction_ts[525 + i] +
                        # coef 9 = B8 (lag 15)
                            coef(pand_model_fixed)[10] * log_diff_prediction_ts[524 + i]
                        # coef 10 = B9 (lag 16)
}

fcast_pandemic_fixed_ts <- ts(fcast_pandemic_fixed, frequency = 12, start = c(2020, 1))

# The following plots the AR(3) and AR(16) fixed forecasts against the actual observations.
plot(covid_pand_housing_prediction_sample)
lines(fcast_pandemic_fixed_ts, col = 'purple')

```

```{r}

# The folowing plots all the AR forecasts for comparision. 
plot(covid_pand_housing_prediction_sample)
lines(fcast_pandemic_fixed_ts, col = 'green', lwd = 2)
lines(fcast_pandemic_recursive_ts, col = 'brown',lwd =1)
lines(fcast_pandemic_rolling_ts, col = 'orange', lwd = 2)
```

## Observation(s):


## Conclusion(s): 
Tradition convention is to choose a simpler model because a simpler model is more likely to reflect the behaviors of a population when you build that model on observations of a sample group. 



## Next Step(s):
1.  