---
title: "Forecasting DTC"
author: "Glen Lewis, Jonathan Burns, Eric Beekman, Andrew Nalundasan"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
# load libraries
library(tidyverse)
library(vtable)
library(jtools)
library(haven)
library(tidylog)
options(scipen=999)
```

# Read in data and wrangle

```{r}
# read in data
data <- read_csv("../02_raw_data/fmhpi_master_file.csv")

# look at the data
head(data, 10)
```


```{r}
# filter for target GEO
puget <- data %>% 
  filter(GEO_Type == 'CBSA', GEO_Name == 'Seattle-Tacoma-Bellevue WA')

puget$YearMonth <- as.Date(with(puget, paste(Year, Month, 1, sep="-")),"%Y-%m-%d")

puget <- puget[, c('YearMonth', 'Index_NSA')] %>% 
  filter(YearMonth >= '2011-01-01')

# declare as TS
puget_q1 <- ts(puget$Index_NSA, frequency=12, start=1975)  # monthly data
```

+ Data wrangling: 

    + filter geography for 'Seattle-Tacoma-Bellevue WA'
    + create new column for 'YearMonth' concatenating to be %Y-%m-%d format
    + filter dataset to be dates from 2011-present for research question 1

# Research Question 1: Forecasting from 2011-present

```{r}
# plot TS
plot(puget_q1, col='blue', main='Seattle, Tacoma, Bellevue\nNon-Seasonally Adjusted index trends', ylab='Non-Seasonally Adjusted Index', xlab='Year')

# plot histogram
hist(puget_q1)
```

**Comments**

+ Need to take difference to achieve stationarity

```{r}

# log difference of puget
ld_puget_q1 <- diff(log(puget_q1))

plot(ld_puget_q1, col='blue', main='Seattle, Tacoma, Bellevue\nLog Difference Index_NSA trends', ylab='Non-Seasonally Adjusted Index', xlab='Year')

# create linear regression for time series data
# model1 <- dynlm(dp ~ lag(dp, -1) + lag(dr, -1))
```

**Comments**

+ After taking the log difference from the TS, does this yield a stationary trend?

    + This looks stationary but need to verify
    
+ What does this tell us?

```{r Plot ACF}
# auto correlation function
# 20 lags
acf(puget_q1, lag.max = 20, main='Puget TS - ACF')

# see values only and no plot
acf(puget_q1, lag.max = 20, plot = FALSE)
```

**Comments**

+ How many lags should we be running?
+ Arbitrarily chose 20 lags
+ Plot never falls below statistically significant threshold in 20 lags

    + PACF will likely fall below threshold before ACF

```{r Plot PACF}
# PACF
pacf(puget_q1, lag.max = 20, main='Puget TS - PACF')

# values only
pacf(puget_q1, lag.max = 20, plot = FALSE)
```

**Comments**

+ PACF falls below statistically significant threshold at lag 2

    + This indicates that we are working with an Auto Regressive (AR) process

**Questions**

+ How many lags should we be running?
    
    + Arbitrarily chose 20 lags
    
+ Does this indicate an ARIMA or ARMA model moving forward?
+ How do we determine what order of AR we are working with?

    + Perhaps once we determine a model?


```{r}
# log difference of ACF and PACF
# log difference ACF
acf(ld_puget_q1, lag.max = 20, main = 'log diff Puget Sound Index_NSA - ACF')

```

**Comments**

+ Coefficients don't drop below significance level until lag 5 
+ Looks like a sinusoidal wave
+ Need to plot PACF logged difference 

```{r}
# log difference PACF
pacf(ld_puget_q1, lag.max = 20, main = 'log diff Puget Sound Index_NSA - PACF')
```

**Comments**

+ Oscillating coefficients indicate a negative number somewhere in the model or something like that
+ PACF drops below significance threshold at lag 5
    
    + Logged difference PACF indicates an AR process as well
    + Is this enough evidence to confirm AR process?
    + How can we verify via calculations?
    
**Questions** 

+ These tests are just visual tests. How do we determine AR vs. MA process computationally?


# Research Question 2: Forecasting from 2011-2019 (pre-pandemic)



# Research Question 3: Forecasting from 2020-2021 (post-pandemic)

